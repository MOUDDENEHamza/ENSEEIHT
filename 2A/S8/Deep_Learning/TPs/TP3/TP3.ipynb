{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMMppWbnG3dN"
   },
   "source": [
    "# Classification d'images de chiens et de chats\n",
    "\n",
    "Dans ce TP, on s'intéresse au problème simple (en apparence) de reconnaître des chiens et des chats dans des images.\n",
    "\n",
    "<center> <img src=\"https://drive.google.com/uc?id=11W1SmzrBhL8vyzPCjSkZfHWnxb7kByi5\" style=\"width:1000;height:550px;\"></center>\n",
    "<caption><center><b> Figure 1 : Quelques images de la base de données </b></center></caption>\n",
    "\n",
    "Pour cela nous allons utiliser une base de données de 4000 images, réparties en 2000 images d'apprentissage, 1000 images de validation, et 1000 images de test. Compte-tenu de la variabilité possible des représentations de chiens et chats, cette base de données est d'une taille assez réduite et le problème est complexe. Il correspond bien aux problèmes que nous pouvons rencontrer dans la réalité, lorsque les données sont souvent difficiles à obtenir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTO3QOJyO2Sq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "from keras import layers, models, optimizers\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3mdNJJXc6Wy"
   },
   "source": [
    "## Chargement des données\n",
    "La base de données est à télécharger depuis Git. Ne passez pas trop de temps à regarder les cellules suivantes (mais exécutez les !), en revanche elles vous fournissent un bon exemple de code pour charger vos propres datasets, **ce qui vous sera utile pour le projet !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_OkpjrpFXXG"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/axelcarlier/iam.git\n",
    "path = \"./iam/tp3/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoSVj5OGXa-4"
   },
   "source": [
    "Création de listes contenant les noms des images des ensemble d'apprentissage, de validation et de test, ainsi que les label (0: chat, 1:chien) associés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diAkv0vEY--X"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "#Images d'entrainement\n",
    "train_filenames_dogs= os.listdir(path + \"train/dogs\")\n",
    "train_filenames_cats= os.listdir(path + \"train/cats\")\n",
    "if not os.path.exists(path + \"train/train\"):\n",
    "  os.mkdir(path + \"train/train\")\n",
    "\n",
    "path_train = path + \"train/\"\n",
    "for filename in train_filenames_cats:\n",
    "  shutil.copyfile(path_train+\"cats/\"+filename, path_train+\"train/\"+filename)\n",
    "for filename in train_filenames_dogs:\n",
    "  shutil.copyfile(path_train+\"dogs/\"+filename, path_train+\"train/\"+filename)\n",
    "\n",
    "train_filenames = os.listdir(path + \"train/train\")\n",
    "train_categories=[]\n",
    "for filename in train_filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        train_categories.append(1)\n",
    "    else:\n",
    "        train_categories.append(0)\n",
    "\n",
    "#Images de validation\n",
    "validation_filenames = os.listdir(path +\"validation/\")\n",
    "validation_categories=[]\n",
    "for filename in validation_filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        validation_categories.append(1)\n",
    "    else:\n",
    "        validation_categories.append(0)\n",
    "\n",
    "#Images de test\n",
    "test_filenames = os.listdir(path + \"test/\")\n",
    "test_categories=[]\n",
    "for filename in test_filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        test_categories.append(1)\n",
    "    else:\n",
    "        test_categories.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEvhzEyyu7P8"
   },
   "source": [
    "Création de DataFrames (structure de données qui permettra plus loins de charger les données au fur et à mesure des besoins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBeikZiD8L0t"
   },
   "outputs": [],
   "source": [
    "#Images d'entrainement\n",
    "train_df = pd.DataFrame({\n",
    "    'filename': train_filenames,\n",
    "    'category': train_categories\n",
    "})\n",
    "\n",
    "\n",
    "#Images de validation\n",
    "validation_df = pd.DataFrame({\n",
    "    'filename': validation_filenames,\n",
    "    'category': validation_categories\n",
    "})\n",
    "\n",
    "\n",
    "#Images de test\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames,\n",
    "    'category': test_categories\n",
    "})\n",
    "\n",
    "\n",
    "train_df['category'] = train_df['category'].astype(str)\n",
    "validation_df['category'] = validation_df['category'].astype(str)\n",
    "test_df['category'] = validation_df['category'].astype(str)\n",
    "\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validation_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwngS1p9V1VN"
   },
   "source": [
    "### Visualisation des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4vHxE7Yp_-u"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "sample = random.choice(test_filenames)\n",
    "image = load_img(path + \"test/\" +sample)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCzCk24sNzC_"
   },
   "source": [
    "### Prétraitement des images\n",
    "\n",
    "La syntaxe ci-dessous définit pour chaque ensemble de données des \"generator\" qui permettent de charger un nombre prédéfini d'images (ce sera notre taille de batch) à partir des DataFrame définies précédemment. On définit également une dimension cible des images (ici, 150x150) et un pré-traitement de normalisation (division par 255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8xfisrdMDGW"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 16\n",
    "image_size = 150\n",
    "\n",
    "\n",
    "#Images d'entrainement\n",
    "train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    path + \"train/train/\",\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(image_size,image_size),\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "#Images de validation\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validation_df, \n",
    "    path + \"validation/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    class_mode='binary',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "#Images de test\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    path + \"test/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    class_mode='binary',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0vwQ7tCRP1r"
   },
   "outputs": [],
   "source": [
    "labels= {0: 'Chat', 1: 'Chien'}\n",
    "labels.get(0), labels.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXUxcuIPOS5W"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    for X_batch, Y_batch in train_generator:\n",
    "        image = X_batch[0]\n",
    "        plt.title(labels.get(Y_batch[0]))\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV5s1T3yWJB6"
   },
   "source": [
    "## Première approche : réseau convolutif de base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00T5cUGlif9z"
   },
   "source": [
    "Les images ont toutes été redimensionnées en $150\\times150$. Nous pouvons donc définir notre réseau de neurones convolutif en suivant ce schéma : \n",
    "\n",
    "<center> <img src=\"https://drive.google.com/uc?id=1bwXaIgO-pKJGs6fVaX0IrLbFbUAlTvNM\" style=\"width:800;height:400px;\"></center>\n",
    "<caption><center><b> Figure 2: Vue de l'architecture à implémenter </b></center></caption>\n",
    "\n",
    "Ce réseau alterne dans une première phase les couches de convolution et de Max Pooling (afin de diviser à chaque fois la dimension des tenseurs par 2). \n",
    "\n",
    "La première couche comptera 32 filtres de convolution, la seconde 64, la troisième 96 et la 4e 128. Enfin, avant la couche de sortie, vous ajouterez une couche dense comptant 512 neurones. Vous aurez donc construit un réseau à 6 couches, sorte de version simplifiée d'AlexNet.\n",
    "\n",
    "Pour construire ce réseau, vous pouvez utiliser les fonctions Conv2D, Maxpooling2D, et Flatten de Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktYvE7Poiyhm"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "# A COMPLETER\n",
    "# model.add(Conv2D(...))\n",
    "# model.add(MaxPooling2D(..))\n",
    "# ...\n",
    "# model.add(Flatten())    # \"Mise à plat\" (vectorisation) du tenseur pour permettre de la connecter à une couche dense  \n",
    "# model.add(Dense(...))   # Couche dense, à 512 neurones\n",
    "# model.add(Dense(...))   # Couche de sortie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PtQwoedfbvk0"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWqVtzWZIsOY"
   },
   "source": [
    "### Entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q9IQIETzLI-"
   },
   "source": [
    "Pour l'entraînement, vous pouvez utiliser directement les hyperparamètres suivants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJsJ7mMIjCGm"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=3e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... puis lancer l'entraînement. **Attention : si jamais vous voulez relancer l'entraînement, il faut réinitialiser les poids du réseau. Pour cela il faut re-exécuter les cellules précédentes à partir de la définition du réseau !** Sinon vous risquez de repartir d'un entraînement précédent (qui s'est éventuellement bien, ou mal déroulé) et mal interpréter votre nouvel entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjetcQRljJC8"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, validation_data=validation_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBPk-patWSYX"
   },
   "source": [
    "### Analyse des résultats du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "casoAuXmzWYb"
   },
   "source": [
    "Les quelques lignes suivantes permettent d'afficher l'évolution des métriques au cours de l'entraînement, sur les ensembles d'apprentissage et de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fExCbSI3V6Ur"
   },
   "outputs": [],
   "source": [
    "def plot_training_analysis():\n",
    "  acc = history.history['acc']\n",
    "  val_acc = history.history['val_acc']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(epochs, acc, 'b', linestyle=\"--\",label='Training acc')\n",
    "  plt.plot(epochs, val_acc, 'g', label='Validation acc')\n",
    "  plt.title('Training and validation accuracy')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(epochs, loss, 'b', linestyle=\"--\",label='Training loss')\n",
    "  plt.plot(epochs, val_loss,'g', label='Validation loss')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex3AjPOPu2UN"
   },
   "outputs": [],
   "source": [
    "plot_training_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ochTgkyqwHIe"
   },
   "source": [
    "### Correction du surapprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXb2ZxKv4gpi"
   },
   "source": [
    "Vous devriez maintenant reconnaître le problème auquel vous avez affaire : **le surapprentissage**. Ce problème est classique dès lors que l'on travaille sur des bases de données de taille réduite en apprentissage profond.\n",
    " En effet, le réseau que vous avez créé compte normalement (si vous avez suivi les indications) plus de trois millions de paramètres. Le problème que vous essayez de résoudre pendant l'entraînement consiste à établir 3 millions de paramètres avec seulement 2000 exemples : c'est trop peu !\n",
    "\n",
    "Afin de limiter ce surapprentissage, nous pouvons appliquer les techniques de régularisation vues pendant le 2nd cours. En traitement d'image, une des techniques les plus couramment utilisées est **l'augmentation de la base de données**.\n",
    "\n",
    "Nous allons reprendre l'ImageDataGenerator créé précédemment pour normaliser les images et l'utiliser  pour appliquer des transformations supplémentaires aux images de notre base de données. A vous de chercher dans la documentation à quoi correspondent les différents paramètres présentés ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90Wlyt6Gwm6v"
   },
   "outputs": [],
   "source": [
    "train_datagen_2 = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "train_generator_augmented = train_datagen_2.flow_from_dataframe(\n",
    "    train_df, \n",
    "    path + 'train/train/',\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(image_size,image_size),\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivante vous permet de visualiser des images passées à travers notre boucle d'augmentation de données. Observez comment les valeurs manquantes (par exemple, dans le cas d'une rotation) sont comblées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_x, example_y = train_generator_augmented.next()\n",
    "for i in range(0,1):\n",
    "    plt.imshow(example_x[i])\n",
    "    plt.title(labels.get(example_y[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdqsPbKm5TkR"
   },
   "source": [
    "Nous pouvons maintenant recréer notre modèle et relancer l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJLABQ67yLms"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "# A COMPLETER\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=3e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_generator_augmented, \n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=50,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM2CLNX8wbfv"
   },
   "source": [
    "### Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9smZiILLyt8g"
   },
   "outputs": [],
   "source": [
    "plot_training_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_JbNoF46le7"
   },
   "source": [
    "On voit clairement sur les courbes que l'on a limité le sur-apprentissage. Notez aussi d'ailleurs, et c'est important, que l'apprentissage est plus lent : le modèle met plus de temps à prédire correctement l'ensemble d'apprentissage. C'est normal, car on a en quelque sorte \"complexifié le problème\" en introduisant toutes ces déformations de nos images.\n",
    "Cette forme de régularisation \"par les données\" s'ajoute aux autres méthodes que nous avons vues précédemment comme la régularisation L1/L2 des poids du réseau et le Dropout.  \n",
    "\n",
    "Vous devriez maintenant atteindre des performances autour de 80% de précision sur l'ensemble de validation, ce qui est bien mais pas complètement satisfaisant : il faudrait pour continuer à s'améliorer probablement s'entraîner plus longtemps, mais également disposer de plus de données.\n",
    "\n",
    "Une autre solution est d'utiliser le **Transfer Learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVFqfXs9GrKe"
   },
   "source": [
    "# Transfer learning\n",
    "\n",
    "L'une des raisons qui peut expliquer le fait que nos résultats soient décevants est que les premières couches de notre réseau convolutif, sensées détecter des caractéristiques utiles pour discriminer chiens et chats, n'ont pas appris de filtres suffisamment généraux à partir des 2000 images d'entraînement. Ainsi, même si ces filtres sont pertinents pour les 2000 images d'entraînement, il y a en fait assez peu de chances que ces filtres puissent bien fonctionner pour la généralisation sur de nouvelles données.\n",
    "\n",
    "C'est la raison pour laquelle nous avons envie de réutiliser un réseau pré-entrainé sur une large base de données, permettant donc de détecter des caractéristiques qui généraliseront mieux à de nouvelles données.\n",
    "\n",
    "Dans cette partie, nous allons réutiliser un réseau célèbre, et d'ores et déjà entraîné sur la base de données ImageNet : le réseau VGG-16.\n",
    "\n",
    "Commençons par récupérer les couches de convolution de ce réseau, et s'en remémorer  la composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRWY8mEQuF9O"
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet', # On utilise les poids du réseau déjà pré-entrainé sur la base de données ImageNet\n",
    "                  include_top=False, # On ne conserve pas la partie Dense du réseau originel\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xv_jCMwkuHY4"
   },
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKyLfZcwOYwH"
   },
   "source": [
    "Nous pouvons extraire les caractéristiques, apprises par le réseau de neurones sur ImageNet, de notre base de données d'image de chiens et de chat. L'intérêt, par rapport à la première partie, est qu'il aurait été presque impossible de déduire ces caractéristiques \"générales\" (trouvées sur une immense base de données) depuis notre base de données trop réduite de 2000 images. En revanche, ces caractéristiques générales devraient se révéler utiles pour notre classifieur.\n",
    "\n",
    "On peut lire sur la structure du réseau VGG résumée grâce à la fonction *summary* ci-dessus que le tenseur de sortie est de dimension $4 \\times 4 \\times 512$, autrement dit que le réseau prédit des caractéristiques de dimension $4 \\times 4 \\times 512$ à partir d'une image de taille $150 \\times 150$.\n",
    "\n",
    "On va redimensionner cette sortie dans un vecteur de dimension $8192 = 4 \\times 4 \\times 512$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "op4vvD9_ugWL"
   },
   "outputs": [],
   "source": [
    "train_features = conv_base.predict(train_generator)\n",
    "train_features = np.reshape(train_features,(train_features.shape[0],4*4*512))\n",
    "\n",
    "val_features = conv_base.predict(validation_generator)\n",
    "val_features = np.reshape(val_features,(val_features.shape[0],4*4*512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Itn1SFzOxNAg"
   },
   "source": [
    "Il nous faut également récupérer les labels associés ; nous allons les chercher dans la dataframe définie au début du TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0MgMopJXwnEQ"
   },
   "outputs": [],
   "source": [
    "train_data = train_df.to_numpy()\n",
    "y_train = np.array([int(numeric_string) for numeric_string in train_data[:,1]])\n",
    "\n",
    "validation_data = validation_df.to_numpy()\n",
    "y_val = np.array([int(numeric_string) for numeric_string in validation_data[:,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0A_ayR0dvvwe"
   },
   "source": [
    "Nous pouvons maintenant définir un réseau de neurones simple qui va travailler directement sur les caractéristiques prédites par VGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmmBYYmtvUUF"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4*4*512))\n",
    "model.add(layers.Dropout(0.5)) # On utilise du DropOut sur cette couche dense car elle comporte un grand nombre\n",
    "                               # de paramètres et risque d'être très sujette au sur-apprentissage.\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=3e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(val_features, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CFd7e-dJ-cK"
   },
   "source": [
    "On observe à nouveau beaucoup de sur-apprentissage. Il faudrait trouver un moyen d'intégrer de l'augmentation de données. \n",
    "\n",
    "Pour cela, on peut connecter notre petit réseau de neurones à l'extrémité de la base convolutionnelle de VGG. L'idée est qu'en réutilisant notre générateur de données augmentées, nous pourrons calculer les caractéristiques de VGG sur les données augmentées, et ainsi classifier ces caractéristiques plutôt que les caractéristiques de notre base de données uniquement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8W85VMorXPtP"
   },
   "source": [
    "## Intégration de l'augmentation de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCb_itsuXenK"
   },
   "source": [
    "### Définition du nouveau modèle et entrainement\n",
    "\n",
    "On commence par créer un nouveau modèle qui va s'appuyer sur la base convolutive de VGG, à laquelle on adjoint une couche dense et notre couche de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyZZS-GSKyPZ"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZr_u4s7K4Fi"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRiiu2EbBNAv"
   },
   "source": [
    "**Attention** : il est important de ne pas commander l'entraînement de la base convolutionnelle de VGG ! Nous ne voulons en aucun cas écraser les bonnes caractéristiques de VGG que nous cherchons justement à réutiliser ! Le réseau aurait en outre un grand nombre de paramètres, ce qui est justement ce que l'on veut éviter ! \n",
    "\n",
    "Pour cela nous pouvons utiliser l'attribut *trainable* : en le positionnant à *false*, nous pouvons geler les poids et en empêcher la mise à jour pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9h8Fx8P0PId5"
   },
   "outputs": [],
   "source": [
    "conv_base.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observez le décompte des poids : le nombre de poids entraînable est maintenant à 2 millions, contre 16 millions précédemment ; on ne va entrainer ici que les poids de notre couche dense et de la couche de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "go7Uld7sLRdG"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=3e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator_augmented,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-RNeMcAXu8h"
   },
   "source": [
    "### Analyse des résultats du nouveau modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJWBzO-KCCSh"
   },
   "source": [
    "L'entraînement est beaucoup plus lent ! Il faut en effet générer les données augmentées, et leur faire traverser les couches de VGG à chaque itération de gradient. Ceci prend du temps !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DHOFSauLyJa"
   },
   "outputs": [],
   "source": [
    "plot_training_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac4pNlvJCtkY"
   },
   "source": [
    "En revanche, on observe que l'on a bien limité le sur-apprentissage, ce qui était le but recherché. Cela améliore considérablement les résultats !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmykKP9_M1GW"
   },
   "source": [
    "### Fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4pV9QlhFc_8"
   },
   "source": [
    "Nous pouvons maintenant tester la dernière technique vue en cours : le **fine-tuning**. Pour cela, nous allons repartir du réseau que nous venons d'entraîner, mais nous allons débloquer l'entraînement des poids de l'ensemble du réseau. **ATTENTION : il est important de choisir un taux d'apprentissage très faible afin de ne pas réduire à néant les bénéfices des entraînements précédents.** L'objectif est simplement de faire évoluer les paramètres du réseau \"à la marge\", et ceci ne peut être fait qu'après la première étape de *transfer learning* précédente. Sans cela, les dernières couches ajoutées à la suite de la base convolutive, après leur initialisation aléatoire, auraient engendré de forts gradients qui auraient complètement détruit les filtres généraux de VGG.\n",
    "\n",
    "\n",
    "\n",
    "On commence par réactiver l'entraînement des paramètres de la base convolutive de VGG : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeZA3eVYEJDY"
   },
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9SvUKcWEPVd"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-5), # Taux d'apprentissage réduit pour ne pas tout casser, ni risquer le sur-apprentissage !\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator_augmented,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCK-hm_IN0P4"
   },
   "outputs": [],
   "source": [
    "plot_training_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hCLsD6tpGhm"
   },
   "source": [
    "On atteint l'excellent résultat de 97% de précision sur l'ensemble de validation, bien au-dessus des performances obtenues sans *transfer learning* ! Vous comprenez maintenant pourquoi en traitement d'image, cette technique est incontournable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VptFMmkArNqi"
   },
   "source": [
    "**Questions (si vous avez du temps, et qui vous serviront pour le projet)** :\n",
    "\n",
    "\n",
    "\n",
    "*   En réalité, on utilise plus vraiment la couche Flatten() aujourd'hui pour faire le lien entre couches convolutives et couches denses, mais plutôt une couche de [GlobalAveragePooling()](https://keras.io/api/layers/pooling_layers/global_average_pooling2d/). Essayez de comprendre ce que fait cette couche et de modifier le réseau construit par dessus VGG en conséquence. \n",
    "*   Essayez de charger d'autres modèles que VGG16 au début de ce TP. Vous trouverez sur la doc de Keras [une liste des modèles utilisables](https://keras.io/api/applications/). Vous pouvez par exemple tester des réseaux plus avancés, que nous verrons dans la suite du cours, comme par exemple Inception et ResNet. Quel réseau fournit les meilleurs résultats ? (Attention à bien lire la documentation, certains réseaux comme EfficientNet prennent en entrée des images non normalisées, ce qui nécessite des modifications dans l'ImageDataGenerator défini plus haut).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "IAM2020 - TP3 - Classification de chiens et chats.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

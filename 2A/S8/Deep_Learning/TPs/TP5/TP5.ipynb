{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMMppWbnG3dN"
   },
   "source": [
    "\n",
    "# Estimation de posture dans une image\n",
    "\n",
    "Pour ce TP ainsi que le suivant, nous allons traiter le problème de la détection du \"squelette\" d'un humain dans une image, tel qu'illustré dans la figure ci-dessous.\n",
    "\n",
    "![Texte alternatif…](https://drive.google.com/uc?id=1HpyLwzwkFdyQ6APoGZQJL7f837JCHNkh)\n",
    "\n",
    "Nous allons pour ce faire utiliser le [Leeds Sport Pose Dataset](https://sam.johnson.io/research/lspet.html) qui introduit 10000 images présentant des sportifs dans diverses situations, augmentées d'une annotation manuelle du squelette.\n",
    "\n",
    "À chaque image est associée une matrice de taille 3x14, correspondant aux coordonnées dans l'image des 14 joints du squelette de la personne décrite dans l'image. La 3e dimension désigne la visibilité du joint (1 s'il est visible, 0 s'il est occulté)\n",
    "\n",
    "Ces joints sont, dans l'ordre :\n",
    "*   Cheville droite\n",
    "*   Genou droit\n",
    "*   Hanche droite\n",
    "*   Hanche gauche\n",
    "*   Genou gauche\n",
    "*   Cheville gauche\n",
    "*   Poignet droit\n",
    "*   Coude droit\n",
    "*   Épaule droite\n",
    "*   Épaule gauche\n",
    "*   Coude gauche\n",
    "*   Poignet gauche\n",
    "*   Cou\n",
    "*   Sommet du crâne\n",
    "\n",
    "Pour un rappel des notions vues en cours sur ce sujet, vous pouvez regarder la vidéo ci-dessous :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "COfRON-Mp1Iu",
    "outputId": "de87203e-6a40-4b8a-97a7-d8e75d2add8f"
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"https://video.polymny.studio/?v=84ace9c1-f460-4375-9b33-917c3ff82c83/\", width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3mdNJJXc6Wy"
   },
   "source": [
    "Commencez par télécharger la base de données sur Github\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3IVjmLKWRDag",
    "outputId": "e379813a-588c-451c-a8b5-0ef9ba466b79"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/axelcarlier/lsp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quOHEF__pf36",
    "outputId": "c7d5d0d5-5769-43a5-ea51-e5c79f269bf9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Cette fonction permettra plus tard de charger plus ou moins d'images (en modifiant le paramètre num_images)\n",
    "# et de modifier la dimension d'entrée\n",
    "def load_data(image_size=128, num_images=1000):\n",
    "\n",
    "  path = \"./lsp/images/\"\n",
    "  dirs = sorted(os.listdir(path))\n",
    "\n",
    "  x = np.zeros((min(num_images,len(dirs)),image_size,image_size,3))\n",
    "  y = np.zeros((min(num_images,len(dirs)), 3, 14))\n",
    "    \n",
    "  #Chargement des joints    \n",
    "  mat_contents = loadmat('./lsp/joints.mat')\n",
    "  joints = mat_contents['joints']\n",
    "\n",
    "  # Chargement des images, qui sont rangées dans lsp/images\n",
    "  for i in range(min(num_images,len(dirs))):\n",
    "    item = dirs[i]\n",
    "    if os.path.isfile(path+item):\n",
    "        img = Image.open(path+item)\n",
    "        # Redimensionnement et sauvegarde des joints\n",
    "        y[i, 0] = joints[:,0,i]*image_size/img.size[0]\n",
    "        y[i, 1] = joints[:,1,i]*image_size/img.size[1]\n",
    "        y[i, 2] = joints[:,2,i]\n",
    "        # Redimensionnement et sauvegarde des images        \n",
    "        img = img.resize((image_size,image_size))\n",
    "        x[i] = np.asarray(img)\n",
    "\n",
    "\n",
    "  return x, y\n",
    "\n",
    "# Chargement de seulement 10 images, de taille 64x64\n",
    "x, y = load_data(image_size=64, num_images=10)           \n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRc0B4oxe6h_"
   },
   "outputs": [],
   "source": [
    "labels= {0: 'Cheville droite',\n",
    "         1: 'Genou droit',\n",
    "         2: 'Hanche droite',\n",
    "         3: 'Hanche gauche',\n",
    "         4: 'Genou gauche',\n",
    "         5: 'Cheville gauche',\n",
    "         6: 'Poignet droit',\n",
    "         7: 'Coude droit',\n",
    "         8: 'Épaule droite',\n",
    "         9: 'Épaule gauche',\n",
    "         10: 'Coude gauche',\n",
    "         11: 'Poignet gauche',\n",
    "         12: 'Cou',\n",
    "         13: 'Sommet du crâne'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meezS1y4G8QO"
   },
   "source": [
    "La fonction suivante vous permet de visualiser les données. Vous vous rendrez compte que certaines données sont manquantes ! En effet quand des joints sont occultés dans les images, des valeurs de position aberrantes (négatives) sont indiquées. Dans ce cas, nous n'afficherons pas les articulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "JvcqdQIZdCYk",
    "outputId": "f0f31fa8-601b-4484-c2a0-1bfc05bf6e99"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fonction d'affichage d'une image et de son label associé\n",
    "def print_data(x,y,i):\n",
    "    \n",
    "  if y.shape[1] < 3:\n",
    "    y_new = np.ones((y.shape[0], 3, y.shape[2]))\n",
    "    y_new[:,0:2,:] = y\n",
    "    y = y_new\n",
    "    \n",
    "  plt.figure(figsize=(5, 5))\n",
    "  plt.imshow(x[i]/255)\n",
    "  for j in range(0,14):\n",
    "    if y[i, 2, j] == 1:\n",
    "        plt.scatter(y[i,0,j],y[i,1,j],label=labels.get(j))\n",
    "\n",
    "  # Jambe droite      \n",
    "  if (y[i, 2, 0] + y[i, 2, 1] == 2):\n",
    "      plt.plot(y[i,0,0:2],y[i,1,0:2],'b')\n",
    "  # Cuisse droite      \n",
    "  if (y[i, 2, 1] + y[i, 2, 2] == 2):\n",
    "      plt.plot(y[i,0,1:3],y[i,1,1:3],'b')\n",
    "  # Bassin     \n",
    "  if (y[i, 2, 2] + y[i, 2, 3] == 2):\n",
    "      plt.plot(y[i,0,2:4],y[i,1,2:4],'b')\n",
    "  # Cuisse gauche      \n",
    "  if (y[i, 2, 3] + y[i, 2, 4] == 2):\n",
    "      plt.plot(y[i,0,3:5],y[i,1,3:5],'b')\n",
    "  # Jambe gauche      \n",
    "  if (y[i, 2, 4] + y[i, 2, 5] == 2):\n",
    "      plt.plot(y[i,0,4:6],y[i,1,4:6],'b')\n",
    "  # Avant-bras droit      \n",
    "  if (y[i, 2, 6] + y[i, 2, 7] == 2):\n",
    "      plt.plot(y[i,0,6:8],y[i,1,6:8],'b')\n",
    "  # Bras droit      \n",
    "  if (y[i, 2, 7] + y[i, 2, 8] == 2):\n",
    "      plt.plot(y[i,0,7:9],y[i,1,7:9],'b')\n",
    "  # Bras gauche     \n",
    "  if (y[i, 2, 9] + y[i, 2, 10] == 2):\n",
    "      plt.plot(y[i,0,9:11],y[i,1,9:11],'b')\n",
    "  # Avant-bras gauche      \n",
    "  if (y[i, 2, 10] + y[i, 2, 11] == 2):\n",
    "      plt.plot(y[i,0,10:12],y[i,1,10:12],'b') \n",
    "  # Buste droit\n",
    "  x1=[y[i,0,2],y[i,0,12]]\n",
    "  y1=[y[i,1,2],y[i,1,12]]\n",
    "  if (y[i, 2, 2] + y[i, 2, 12] == 2):\n",
    "      plt.plot(x1, y1,'b')\n",
    "  # Buste gauche\n",
    "  x1=[y[i,0,3],y[i,0,12]]\n",
    "  y1=[y[i,1,3],y[i,1,12]]\n",
    "  if (y[i, 2, 3] + y[i, 2, 12] == 2):\n",
    "      plt.plot(x1, y1,'b')\n",
    "  # Omoplate droite\n",
    "  x1=[y[i,0,8],y[i,0,12]]\n",
    "  y1=[y[i,1,8],y[i,1,12]]\n",
    "  if (y[i, 2, 8] + y[i, 2, 12] == 2):\n",
    "      plt.plot(x1, y1,'b')\n",
    "  # Omoplate gauche\n",
    "  x1=[y[i,0,9],y[i,0,12]]\n",
    "  y1=[y[i,1,9],y[i,1,12]]\n",
    "  if (y[i, 2, 9] + y[i, 2, 12] == 2):\n",
    "      plt.plot(x1, y1,'b')\n",
    "  # Tete     \n",
    "  if (y[i, 2, 12] + y[i, 2, 13] == 2):\n",
    "      plt.plot(y[i,0,12:14],y[i,1,12:14],'b')\n",
    "\n",
    "  plt.axis([0, x.shape[1], x.shape[2], 0])\n",
    "  plt.show()\n",
    "  #plt.legend()\n",
    "\n",
    "# Affichage aléatoire d'une image\n",
    "print_data(x,y,np.random.randint(x.shape[0]-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WueEErACp1Iy"
   },
   "source": [
    "Si nous formulons ce problème comme une régression, nous allons utiliser pour évaluer nos réseaux de neurones l'erreur quadratique moyenne (fonction *MSE*). Cette fonction sera parfaite comme fonction de perte, mais elle ne permet pas d'appréhender les résultats de manière satisfaisante.\n",
    "\n",
    "Une métrique commune en estimation de posture est le **PCK0.5**, pour *Percentage of Correct Keypoints*. *0.5* correspond à un seuil en-deça duquel on considère qu'un joint est correctement estimé. Cette question du seuil est particulièrement sensible car il faut utiliser une valeur qui soit valable pour n'importe quelle image. La personne considérée peut apparaître plus ou moins largement sur l'image, de face ou de profil, ce qui fait qu'une erreur de prédiction sur un joint peut avoir une importance très grande ou très faible selon les cas.\n",
    "\n",
    "Pour résoudre cette ambiguïté, on considère dans la métrique du **PCK0.5** que la référence est la taille de la tête, définie par la distance entre le joint du cou et le joint de la tête sur la vérité terrain. Un joint prédit par le réseau sera considéré correct s'il est situé à une distance inférieure à la moitié (*0.5*) de la taille de la tête par rapport au joint réel. ([Andriluka et al.] 2D Human Pose Estimation: New Benchmark and State of the Art Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZjjvx9cp1Iz"
   },
   "outputs": [],
   "source": [
    "import numpy.matlib \n",
    "\n",
    "# Calcul du \"Percentage of Correct Keypoint\" avec seuil alpha :\n",
    "# On compte corrects les joints pour lesquels la distance entre valeurs réelle et prédite \n",
    "# est inférieure à alpha fois la dimension de la tête (c'est un peu arbitraire...)\n",
    "# On ne comptera pas les joints invisibles.\n",
    "# y_true est de dimension Nx3x14 et y_pred Nx2x14 (le réseau ne prédit pas la visibilité)\n",
    "def compute_PCK_alpha(y_true, y_pred, alpha=0.5):\n",
    "    # Calcul des seuils ; la taille de la tête est la distance entre joints 12 et 13\n",
    "    head_sizes = np.sqrt(np.square(y_true[:,0,13]-y_true[:,0,12])+np.square(y_true[:,1,13]-y_true[:,1,12]))\n",
    "    thresholds = alpha*head_sizes\n",
    "    thresholds = np.matlib.repmat(np.expand_dims(thresholds, 1), 1, 14)\n",
    "\n",
    "    # Calcul des distances inter-joints\n",
    "    joints_distances = np.sqrt(np.square(y_true[:,0,:]-y_pred[:,0,:]) + np.square(y_true[:,1,:]-y_pred[:,1,:]))\n",
    "\n",
    "    # Visibilité des joints de la vérité terrain\n",
    "    visibility = y_true[:,2,:]\n",
    "    \n",
    "    total_joints = np.count_nonzero(visibility==1)\n",
    "    correctly_predicted_joints = np.count_nonzero(np.logical_and(joints_distances<thresholds, visibility == 1))\n",
    "    \n",
    "    return correctly_predicted_joints/total_joints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVmEnDdyB-_E"
   },
   "source": [
    "## Petit retour sur le TP précédent : \n",
    "\n",
    "Si vous n'êtes pas allés jusqu'au bout du TP précédent, sachez que même avec un réseau bien construit, de capacité suffisante, en utilisant les 10000 images de la base d'apprentissage, de la régularisation et de l'augmentation de données (non demandé dans le TP), vous ne seriez pas arrivé à limiter le sur-apprentissage suffisamment pour obtenir des résultats satisfaisants sur l'ensemble de test. On plafonne à un pourcentage de joints correctement prédits (PCK@0.5) aux alentours de 20\\%.\n",
    "\n",
    "Cela est principalement dû à la formulation du problème, plus difficile à résoudre, et aux architectures mises en place. En effet, les couches de sous-échantillonnage (*pooling*) successives entraînent une perte de précision irrémédiable qui ne peut pas être compensée par les couches denses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5rCr8gKCEnp"
   },
   "source": [
    "# Prédiction de cartes de chaleur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrL2qpnoD0Lj"
   },
   "source": [
    "Dans ce TP, nous allons utiliser une autre formulation du problème, présentée pendant le cours. Plutôt que de prédire directement la position pixellique des joints, nous allons prédire des cartes de probabilité de la position des joints, comme illustré ci-dessous. Pour ce faire, il nous faudra tester des architectures de réseau de neurones différentes, s'inspirant de celles utilisées en segmentation d'image.\n",
    "\n",
    "![Texte alternatif…](https://drive.google.com/uc?id=1B8BCwQ0Szg_T_H05mnfpXFemUT5xhfxX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Pqj24fMz78h"
   },
   "source": [
    "## Fonctions utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyh-VbYvEppj"
   },
   "source": [
    "La fonction suivante permet de créer une carte de chaleur de la dimension voulue, avec une gaussienne centrée en un point donné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "0u_t30vIEv1P",
    "outputId": "9421ae03-5b45-4e2a-f5be-91006fc2685d"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def heat_point(ind_x, ind_y, heatmap_size):\n",
    "  heat_point=np.zeros((heatmap_size,heatmap_size))\n",
    "  heat_point[ind_x][ind_y] = 1\n",
    "\n",
    "  return gaussian_filter(heat_point, round(heatmap_size/20))\n",
    "\n",
    "h_m = heat_point(14, 44, 64)\n",
    "plt.imshow(h_m)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1vQKbeBGI9g"
   },
   "source": [
    "On peut ensuite retrouver la position du point le plus \"chaud\", en utilisant la commande suivante : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8yWcAk4lGIPa",
    "outputId": "c16937c5-c03f-4922-a288-fc0aa5e4186f"
   },
   "outputs": [],
   "source": [
    "np.unravel_index(np.argmax(h_m), h_m.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiLiDhPjGieb"
   },
   "source": [
    "On peut donc définir les 2 fonctions suivantes permettant de générer les cartes de chaleur à partir des coordonnées de joints, et vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fD3PoNusGhC2"
   },
   "outputs": [],
   "source": [
    "def coord2heatmap(y, heatmap_size):\n",
    "  heatmap = np.zeros((y.shape[0], 14, heatmap_size, heatmap_size))\n",
    "  for img in range(y.shape[0]):\n",
    "    for j in range(14):\n",
    "      ind_x = int(y[img][1][j])\n",
    "      ind_y = int(y[img][0][j])\n",
    "      #print(ind_x, ind_y)\n",
    "      if ind_x >= 0 and ind_y >= 0 and ind_x < heatmap_size and ind_y < heatmap_size:\n",
    "        heatmap[img][j] = heat_point(ind_x, ind_y, heatmap_size)\n",
    "  heatmap = np.transpose(heatmap, (0, 2, 3, 1))\n",
    "  heatmap = heatmap / np.max(heatmap)\n",
    "  return heatmap\n",
    "\n",
    "def heatmap2coord(heatmap):\n",
    "  y = np.ones((heatmap.shape[0], 3, 14))\n",
    "\n",
    "  heatmap = np.transpose(heatmap, (0, 3, 1, 2))\n",
    "  for img in range(y.shape[0]):\n",
    "    for j in range(14): \n",
    "      max_heat = np.unravel_index(np.argmax(heatmap[img][j]),heatmap[img][j].shape)  \n",
    "      y[img][0][j] = max_heat[1]\n",
    "      y[img][1][j] = max_heat[0]\n",
    "      if max_heat[0] == 0 and max_heat[1] == 0:\n",
    "        y[img][2][j] = 0 # Le joint est invisible\n",
    "  return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG0BlJ3LH2kP"
   },
   "source": [
    "Fonction d'affichage des cartes de chaleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCfWl8ncH5JQ"
   },
   "outputs": [],
   "source": [
    "def print_heatmap(x, y, rows=3):\n",
    "  hm = np.transpose(y, (0,3,1,2))\n",
    "\n",
    "  for i in range(rows):\n",
    "    j=np.random.randint(1,x.shape[0])\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    # Affichage de l'image\n",
    "    plt.subplot(rows,5,5*i+1)\n",
    "    plt.imshow(x[j])\n",
    "    plt.title('Image originale')\n",
    "    # Affichage simultané de tous les joints\n",
    "    plt.subplot(rows,5,5*i+2)\n",
    "    joints=np.zeros((y.shape[1], y.shape[2]))\n",
    "    for k in range(14):\n",
    "      joints+= hm[j][k]\n",
    "    plt.imshow(joints)\n",
    "    plt.title('Tous les joints')\n",
    "\n",
    "    plt.subplot(rows, 5, 5*i+3)\n",
    "    plt.imshow(hm[j][13])\n",
    "    plt.title('Tête')\n",
    "    plt.subplot(rows, 5, 5*i+4)\n",
    "    plt.imshow(hm[j][7])\n",
    "    plt.title('Coude droit')\n",
    "    plt.subplot(rows, 5, 5*i+5)\n",
    "    plt.imshow(hm[j][4])\n",
    "    plt.title('Genou gauche')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9QKb9YLJRr4"
   },
   "source": [
    "Les lignes suivantes vous permettront de démarrer simplement : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "fwcCfcazJQL7",
    "outputId": "e4a9c11b-d7f6-4af9-f7a1-20e7dd01abfa"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chargement des données : on choisit une dimension d'image et de carte de chaleur de 64x64\n",
    "image_size = 64\n",
    "heatmap_size = 64\n",
    "\n",
    "# Chargement de seulement 1000 images\n",
    "# Chargement des données : 1000 images d'apprentissage, 100 de validation, 100 de test    \n",
    "x, y = load_data(image_size=image_size, num_images=1000)  \n",
    "# Normalisation des données\n",
    "x = x/255\n",
    "x_train, x_gen, y_train, y_gen = train_test_split(x, y, test_size=1/10, random_state=2)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_gen, y_gen, test_size=1/2, random_state=1)\n",
    "\n",
    "# Calcul des cartes de chaleur (prend un peu de temps)\n",
    "y_hm_train = coord2heatmap(y_train, heatmap_size)\n",
    "y_hm_val = coord2heatmap(y_val, heatmap_size)\n",
    "y_hm_test = coord2heatmap(y_test, heatmap_size)\n",
    "\n",
    "# Affichage de quelques exemples\n",
    "print_heatmap(x_train, y_hm_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZVbag1MOphZ"
   },
   "source": [
    "Pour vous aider pour la suite, voici ci-dessous une implémentation du réseau UNet, vu en cours sur la segmentation.\n",
    "\n",
    "![Texte alternatif…](https://raw.githubusercontent.com/zhixuhao/unet/master/img/u-net-architecture.png)\n",
    "\n",
    "A vous de l'adapter afin qu'il soit pertinent pour le problème courant (dimensions d'entrée et de sortie, **fonction d'activation de sortie**)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_qMkG8ROoky"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras import *\n",
    "\n",
    "def create_unet(image_size=572):\n",
    "  input_layer=Input((image_size, image_size, 1))\n",
    "\n",
    "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(input_layer)\n",
    "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "  \n",
    "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "  \n",
    "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "  \n",
    "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "  drop4 = Dropout(0.5)(conv4)\n",
    "  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "  drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "  up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "  merge6 = concatenate([drop4,up6], axis = 3)\n",
    "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "  up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "  merge7 = concatenate([conv3,up7], axis = 3)\n",
    "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "  \n",
    "  up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "  merge8 = concatenate([conv2,up8], axis = 3)\n",
    "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "  up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "  merge9 = concatenate([conv1,up9], axis = 3)\n",
    "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "  conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "\n",
    "  model = Model(input_layer, conv10)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vgFsh0DRp1I3",
    "outputId": "f023b707-bfe9-4b84-b466-b52b135bbbe1"
   },
   "outputs": [],
   "source": [
    "model = create_unet(image_size=64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPamKJXZsCff"
   },
   "source": [
    "##  Travail à faire \n",
    "\n",
    "Essayez d'adapter le réseau Unet à votre problème, puis de l'entraîner sur le petit ensemble de données x_train. \n",
    "\n",
    "Plusieurs remarques (**à lire attentivement**) : \n",
    "\n",
    "\n",
    "\n",
    "*  Vous devriez observer beaucoup moins de sur-apprentissage ! Si vos prédictions sur l'ensemble de validation sont aberrantes, c'est que vous avez un bug !!\n",
    "*   Se pose la question de la formulation du problème : dans la mesure où \n",
    "les cartes de chaleur sont assimilables à des cartes de probabilité (entre 0 et 1), on peut certes choisir de conserver une formaulation du problème basée sur la régression, mais il est probablement beaucoup plus optimal de formuler le problème comme de la classification binaire.\n",
    "*   Il y a cependant toujours du sur-apprentissage. Vous pouvez donc augmenter la taille de la base de données à 10000, puis tester différentes possibilités pour diminuer ce sous-apprentissage, notamment l'augmentation de données. Les cellules suivantes vous fournissent des éléments permettant de mettre en place cette augmentation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzghttyGTPvq"
   },
   "source": [
    "## Code fourni pour l'augmentation de données\n",
    "\n",
    "Je vous fournis ici quelques éléments qui vous permettront de mettre en place de l'augmentation de données. \n",
    "Attention l'augmentation rend l'apprentissage plus difficile et en fait plus lent, et vous devrez peut-être augmenter un peu la capacité de votre UNet et le nombre d'epochs pour éviter le sous-apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2U4RIeNTmq_"
   },
   "source": [
    "Albumentation est une librairie implémentant un grand nombre d'opérations d'augmentation de données. Dans le code suivant, deux types d'augmentation sont définies : des transformations spatiales (ShiftScaleRotate), et des transformations colorimétriques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4E-o7eMQTtE5"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from albumentations import (Compose, RandomBrightness, RandomContrast, RandomGamma, ShiftScaleRotate)\n",
    "\n",
    "AUGMENTATIONS_TRAIN = Compose([\n",
    "    ShiftScaleRotate(p=0.5),\n",
    "    RandomContrast(limit=0.2, p=0.5),\n",
    "    RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "    RandomBrightness(limit=0.2, p=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac98mnGJTxNu"
   },
   "source": [
    "La classe Sequence permet de définir l'accès aux données d'entraînement de manière personnalisée, afin par exemple d'implanter des augmentations particulières (c'est le cas ici).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XaGczO0QT0H8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "\n",
    "class LSPDSequence(Sequence):\n",
    "    # Initialisation de la séquence avec différents paramètres\n",
    "    def __init__(self, x_set, y_set, batch_size,augmentations):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "        self.indices1 = np.arange(x_set.shape[0]) \n",
    "        np.random.shuffle(self.indices1) # Les indices permettent d'accéder\n",
    "        # aux données et sont randomisés à chaque epoch pour varier la composition\n",
    "        # des batches au cours de l'entraînement\n",
    "\n",
    "    # Fonction calculant le nombre de pas de descente du gradient par epoch\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    # Application de l'augmentation de données à chaque image du batch et aux\n",
    "    # cartes de probabilités associées\n",
    "    def apply_augmentation(self, bx, by):\n",
    "\n",
    "        batch_x = np.zeros(bx.shape)\n",
    "        batch_y = np.zeros(by.shape)\n",
    "        # Pour chaque image du batch\n",
    "        for i in range(len(bx)):\n",
    "            masks = []\n",
    "            # Les 14 masques associés à l'image sont rangés dans une liste pour \n",
    "            # pourvoir être traités par la librairie Albumentation\n",
    "            for n in range(by.shape[3]):\n",
    "                masks.append(by[i,:,:,n])\n",
    "\n",
    "            img = bx[i]\n",
    "            # Application de l'augmentation à l'image et aux masques\n",
    "            transformed = self.augment(image=img, masks=masks)\n",
    "            batch_x[i] = transformed['image']\n",
    "            batch_y_list = transformed['masks']\n",
    "\n",
    "            # Reconstitution d'un tenseur à partir des masques augmentés\n",
    "            for k in range(by.shape[3]):\n",
    "                batch_y[i,:,:,k] = batch_y_list[k]\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    # Fonction appelée à chaque nouveau batch : sélection et augmentation des données\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n",
    "        batch_y = self.y[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n",
    "        \n",
    "        batch_x, batch_y = self.apply_augmentation(batch_x, batch_y)\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "    # Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "NGBI2gXVT399",
    "outputId": "7ffaedf0-158e-4f1f-ae7a-75bcadc91ee8"
   },
   "outputs": [],
   "source": [
    "# Instanciation d'une Sequence\n",
    "train_gen = LSPDSequence(x_train, y_hm_train, 16, augmentations=AUGMENTATIONS_TRAIN)\n",
    "\n",
    "# Pour tester la séquence, nous sélectionnons les éléments du premier batch et les affichons\n",
    "batch_x, batch_y = train_gen.__getitem__(0)\n",
    "\n",
    "print_heatmap(batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT-ySEuOUCyh"
   },
   "source": [
    "Pour utiliser cette séquence il vous suffit d'appeler la fonction fit de la manière suivante :\n",
    "```python\n",
    "model.fit(train_gen, ...)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DL21_TP5_Estimation_de_Posture.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

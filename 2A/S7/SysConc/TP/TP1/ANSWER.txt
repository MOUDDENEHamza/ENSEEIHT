Exercices


Efficacité de la parallélisation


La durée d’exécution non synchronisée est plus petite que la durée
d’exécution mono grâce au partage de ressources entre threads qui permet une
communication plus efficace entre les différents threads d’un processus
qu’entre deux processus distincts. Là où deux processus séparés doivent
utiliser un mécanisme fourni par le système pour communiquer, les threads
partagent une partie de l’état du processus, notamment sa mémoire.

Le surcoût induit par la gestion des threads :
	Puisqu’on a supposé que le temps idéal est tempsd'execution / N donc
	surcot = [tempsNThreads - (temps1Thread / N)] / tempsNThreads
	

Coût de la cohérence


La valeur finale de compteur ne vaut pas le nombre d’itération, car on a de
l’interférence, supposons que la valeur actuelle est dans la mémoire alors
lorsqu’on ajoute 2 threads en même temps le compteur va s’incrémenter seulement
une fois.

On effectue les incrémentions du compteur en exclusion mutuelle. En plaçant
uniquement l’incrémentation de la boucle interne dans le bloc synchronized. En
plaçant la boucle interne dans le bloc synchronized. On remarque que le nombre
final afficher par le compteur égal au nombre d’itérations car on n’a pas
d’interférence.

On aura le même résultat si on utilise un objet de class
java.util.concurrent.atomic car cette classe propose un ensemble de classes 
« atomiques », qui fournissent un ensemble de méthodes dont l’exécution est
garantie sans interférences. Donc y a pas d’interférence lors de l’exécution.
Le coût c’est l’écart par rapport au meilleur temps d’exécution en utilisant
synchronized.

En utilisant ’Volatile’ le résultat n’est pas garantie, Car on aura de 
l’interférence lors de l’exécution.

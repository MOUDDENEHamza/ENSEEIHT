<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Index des fonctions · Optinum.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="index.html"><img src="assets/logo.png" alt="Optinum.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">Optinum.jl</span></div><form class="docs-search" action="search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="index.html">Accueil</a></li><li><a class="tocitem" href="Sujet.html">Sujet</a></li><li><span class="tocitem">Algorithmes</span><ul><li><a class="tocitem" href="Algorithme_de_newton.html">L&#39;algorithme de Newton local</a></li><li><a class="tocitem" href="Regions_de_confiance.html">La méthode des régions de confiance</a></li><li><a class="tocitem" href="Lagrangien_augmente.html">La méthode du Lagrangien augmenté</a></li></ul></li><li class="is-active"><a class="tocitem" href="fct_index.html">Index des fonctions</a></li><li><a class="tocitem" href="Annexes.html">Annexes</a></li><li><a class="tocitem" href="mise_en_place.html">Installation de Julia et tests unitaires</a></li><li><a class="tocitem" href="FAQ.html">Foire aux Questions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="fct_index.html">Index des fonctions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="fct_index.html">Index des fonctions</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/mathn7/Optinum/blob/master/docs/src/fct_index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Documentation-des-fonctions-1"><a class="docs-heading-anchor" href="#Documentation-des-fonctions-1">Documentation des fonctions</a><a class="docs-heading-anchor-permalink" href="#Documentation-des-fonctions-1" title="Permalink"></a></h1><p>Documentation de toute les fonctions du package Optinum</p><ul><li><a href="fct_index.html#Optinum.Algorithme_De_Newton-Tuple{Function,Function,Function,Any,Any}"><code>Optinum.Algorithme_De_Newton</code></a></li><li><a href="fct_index.html#Optinum.Gradient_Conjugue_Tronque-Tuple{Any,Any,Any}"><code>Optinum.Gradient_Conjugue_Tronque</code></a></li><li><a href="fct_index.html#Optinum.Lagrangien_Augmente-Tuple{Any,Function,Function,Function,Function,Function,Function,Any,Any}"><code>Optinum.Lagrangien_Augmente</code></a></li><li><a href="fct_index.html#Optinum.Pas_De_Cauchy-Tuple{Any,Any,Any}"><code>Optinum.Pas_De_Cauchy</code></a></li><li><a href="fct_index.html#Optinum.Regions_De_Confiance-Tuple{Any,Function,Function,Function,Any,Any}"><code>Optinum.Regions_De_Confiance</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="Optinum.Algorithme_De_Newton-Tuple{Function,Function,Function,Any,Any}" href="#Optinum.Algorithme_De_Newton-Tuple{Function,Function,Function,Any,Any}"><code>Optinum.Algorithme_De_Newton</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Approximation de la solution du problème <span>$\min_{x \in \mathbb{R}^{n}} f(x)$</span> en utilisant l&#39;algorithme de Newton</p><p><strong>Syntaxe</strong></p><pre><code class="language-julia">xk,f_min,flag,nb_iters = Algorithme_de_Newton(f,gradf,hessf,x0,option)</code></pre><p><strong>Entrées :</strong></p><ul><li><strong>f</strong>       : (Function) la fonction à minimiser</li><li><strong>gradf</strong>   : (Function) le gradient de la fonction f</li><li><strong>hessf</strong>   : (Function) la Hessienne de la fonction f</li><li><strong>x0</strong>      : (Array{Float,1}) première approximation de la solution cherchée</li><li><strong>options</strong> : (Array{Float,1})<ul><li><strong>max_iter</strong>      : le nombre maximal d&#39;iterations</li><li><strong>tolCN1</strong>        : la tolérence pour la condition nécessaire d&#39;ordre 1</li><li><strong>tol</strong>           : la tolérence pour les autres critères d&#39;arrêt</li></ul></li></ul><p><strong>Sorties:</strong></p><ul><li><strong>xmin</strong>    : (Array{Float,1}) une approximation de la solution du problème  : <span>$\min_{x \in \mathbb{R}^{n}} f(x)$</span></li><li><strong>f_min</strong>   : (Float) <span>$f(x_{min})$</span></li><li><strong>flag</strong>     : (Integer) indique le critère sur lequel le programme à arrêter<ul><li><strong>0</strong>    : Convergence</li><li><strong>1</strong>    : stagnation du xk</li><li><strong>2</strong>    : stagnation du f</li><li><strong>3</strong>    : nombre maximal d&#39;itération dépassé</li></ul></li><li><strong>nb_iters</strong> : (Integer) le nombre d&#39;itérations faites par le programme</li></ul><p><strong>Exemple d&#39;appel</strong></p><pre><code class="language-">using Optinum
f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2
gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]
hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]
x0 = [1; 0]
options = []
xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f,gradf,hessf,x0,options)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Optinum.Gradient_Conjugue_Tronque-Tuple{Any,Any,Any}" href="#Optinum.Gradient_Conjugue_Tronque-Tuple{Any,Any,Any}"><code>Optinum.Gradient_Conjugue_Tronque</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Minimise le problème : <span>$min_{||s||&lt; \delta_{k}} q_k(s) = s^{t}g + (1/2)s^{t}Hs$</span>                         pour la <span>$k^{ème}$</span> itération de l&#39;algorithme des régions de confiance</p><p><strong>Syntaxe</strong></p><pre><code class="language-julia">sk = Gradient_Conjugue_Tronque(fk,gradfk,hessfk,option)</code></pre><p><strong>Entrées :</strong></p><ul><li><strong>gradfk</strong>           : (Array{Float,1}) le gradient de la fonction f appliqué au point xk</li><li><strong>hessfk</strong>           : (Array{Float,2}) la Hessienne de la fonction f appliqué au point xk</li><li><strong>options</strong>          : (Array{Float,1})<ul><li><strong>delta</strong>    : le rayon de la région de confiance</li><li><strong>max_iter</strong> : le nombre maximal d&#39;iterations</li><li><strong>tol</strong>      : la tolérance pour la condition d&#39;arrêt sur le gradient</li></ul></li></ul><p><strong>Sorties:</strong></p><ul><li><strong>s</strong> : (Array{Float,1}) le pas s qui approche la solution du problème : <span>$min_{||s||&lt; \delta_{k}} q(s)$</span></li></ul><p><strong>Exemple d&#39;appel:</strong></p><pre><code class="language-julia">gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]
hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]
xk = [1; 0]
options = []
s = Gradient_Conjugue_Tronque(gradf(xk),hessf(xk),options)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Optinum.Lagrangien_Augmente-Tuple{Any,Function,Function,Function,Function,Function,Function,Any,Any}" href="#Optinum.Lagrangien_Augmente-Tuple{Any,Function,Function,Function,Function,Function,Function,Any,Any}"><code>Optinum.Lagrangien_Augmente</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Résolution des problèmes de minimisation sous contraintes d&#39;égalités</p><p><strong>Syntaxe</strong></p><pre><code class="language-julia">Lagrangien_Augmente(algo,fonc,contrainte,gradfonc,hessfonc,grad_contrainte,
			hess_contrainte,x0,options)</code></pre><p><strong>Entrées</strong></p><ul><li><strong>algo</strong> 		   : (String) l&#39;algorithme sans contraintes à utiliser:<ul><li><strong>&quot;newton&quot;</strong>  : pour l&#39;algorithme de Newton</li><li><strong>&quot;cauchy&quot;</strong>  : pour le pas de Cauchy</li><li><strong>&quot;gct&quot;</strong>     : pour le gradient conjugué tronqué</li></ul></li><li><strong>fonc</strong> 		   : (Function) la fonction à minimiser</li><li><strong>contrainte</strong>	   : (Function) la contrainte [x est dans le domaine des contraintes ssi <span>$c(x)=0$</span>]</li><li><strong>gradfonc</strong>       : (Function) le gradient de la fonction</li><li><strong>hessfonc</strong> 	   : (Function) la hessienne de la fonction</li><li><strong>grad_contrainte</strong> : (Function) le gradient de la contrainte</li><li><strong>hess_contrainte</strong> : (Function) la hessienne de la contrainte</li><li><strong>x0</strong> 			   : (Array{Float,1}) la première composante du point de départ du Lagrangien</li><li><strong>options</strong>		   : (Array{Float,1})<ol><li><strong>epsilon</strong> 	   : utilisé dans les critères d&#39;arrêt</li><li><strong>tol</strong>         : la tolérance utilisée dans les critères d&#39;arrêt</li><li><strong>itermax</strong> 	   : nombre maximal d&#39;itération dans la boucle principale</li><li><strong>lambda0</strong>	   : la deuxième composante du point de départ du Lagrangien</li><li><strong>mu0,tho</strong> 	   : valeurs initiales des variables de l&#39;algorithme</li></ol></li></ul><p><strong>Sorties</strong></p><ul><li><strong>xmin</strong>		   : (Array{Float,1}) une approximation de la solution du problème avec contraintes</li><li><strong>fxmin</strong> 	   : (Float) <span>$f(x_{min})$</span></li><li><strong>flag</strong>		   : (Integer) indicateur du déroulement de l&#39;algorithme<ul><li><strong>0</strong>    : convergence</li><li><strong>1</strong>    : nombre maximal d&#39;itération atteint</li><li><strong>(-1)</strong> : une erreur s&#39;est produite</li></ul></li><li><strong>niters</strong> 	   : (Integer) nombre d&#39;itérations réalisées</li></ul><p><strong>Exemple d&#39;appel</strong></p><pre><code class="language-julia">using LinearAlgebra
f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2
gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]
hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]
algo = &quot;gct&quot; # ou newton|gct
x0 = [1; 0]
options = []
contrainte(x) =  (x[1]^2) + (x[2]^2) -1.5
grad_contrainte(x) = [2*x[1] ;2*x[2]]
hess_contrainte(x) = [2 0;0 2]
output = Lagrangien_Augmente(algo,f,contrainte,gradf,hessf,grad_contrainte,hess_contrainte,x0,options)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Optinum.Pas_De_Cauchy-Tuple{Any,Any,Any}" href="#Optinum.Pas_De_Cauchy-Tuple{Any,Any,Any}"><code>Optinum.Pas_De_Cauchy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Approximation de la solution du sous-problème <span>$q_k(s) = s^{t}g + (1/2)s^{t}Hs$</span>          avec <span>$s=-t g_k,t &gt; 0,||s||&lt; \delta_k$</span></p><p><strong>Syntaxe</strong></p><pre><code class="language-julia">s1, e1 = Pas_De_Cauchy(gradient,Hessienne,delta)</code></pre><p><strong>Entrées</strong></p><ul><li><strong>gradfk</strong> : (Array{Float,1}) le gradient de la fonction f appliqué au point <span>$x_k$</span></li><li><strong>hessfk</strong> : (Array{Float,2}) la Hessienne de la fonction f appliqué au point <span>$x_k$</span></li><li><strong>delta</strong>  : (Float) le rayon de la région de confiance</li></ul><p><strong>Sorties</strong></p><ul><li><strong>s</strong> : (Array{Float,1}) une approximation de la  solution du sous-problème</li><li><strong>e</strong> : (Integer) indice indiquant l&#39;état de sortie:      si g != 0          si on ne sature pas la boule            e &lt;- 1          sinon            e &lt;- -1      sinon          e &lt;- 0</li></ul><p><strong>Exemple d&#39;appel</strong></p><pre><code class="language-julia">g1 = [0; 0]
H1 = [7 0 ; 0 2]
delta1 = 1
s1, e1 = Pas_De_Cauchy(g1,H1,delta1)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Optinum.Regions_De_Confiance-Tuple{Any,Function,Function,Function,Any,Any}" href="#Optinum.Regions_De_Confiance-Tuple{Any,Function,Function,Function,Any,Any}"><code>Optinum.Regions_De_Confiance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Minimise une fonction en utilisant l&#39;algorithme des régions de confiance avec     - le pas de Cauchy ou     - le pas issu de l&#39;algorithme du gradient conjugue tronqué</p><p><strong>Syntaxe</strong></p><pre><code class="language-julia">xk, nb_iters, f(xk), flag = Regions_De_Confiance(algo,f,gradf,hessf,x0,option)</code></pre><p><strong>Entrées :</strong></p><ul><li><strong>algo</strong>        : (String) string indicant la méthode à utiliser pour calculer le pas<ul><li><strong>&quot;gct&quot;</strong>   : pour l&#39;algorithme du gradient conjugué tronqué</li><li><strong>&quot;cauchy&quot;</strong>: pour le pas de Cauchy</li></ul></li><li><strong>f</strong>           : (Function) la fonction à minimiser</li><li><strong>gradf</strong>       : (Function) le gradient de la fonction f</li><li><strong>hessf</strong>       : (Function) la hessiene de la fonction à minimiser</li><li><strong>x0</strong>          : (Array{Float,1}) point de départ</li><li><strong>options</strong>     : (Array{Float,1})<ul><li><strong>deltaMax</strong>      : utile pour les m-à-j de la région de confiance                <span>$R_{k}=\left\{x_{k}+s ;\|s\| \leq \Delta_{k}\right\}$</span></li><li><strong>gamma1,gamma2</strong> : <span>$0 &lt; \gamma_{1} &lt; 1 &lt; \gamma_{2}$</span> pour les m-à-j de <span>$R_{k}$</span></li><li><strong>eta1,eta2</strong>     : <span>$0 &lt; \eta_{1} &lt; \eta_{2} &lt; 1$</span> pour les m-à-j de <span>$R_{k}$</span></li><li><strong>delta0</strong>        : le rayon de départ de la région de confiance</li><li><strong>max_iter</strong>      : le nombre maximale d&#39;iterations</li><li><strong>tolCN1</strong>        : la tolérence pour la condition nécessaire d&#39;ordre 1</li><li><strong>tol</strong>           : la tolérence pour les autres critères d&#39;arrêt</li></ul></li></ul><p><strong>Sorties:</strong></p><ul><li><strong>xmin</strong>    : (Array{Float,1}) une approximation de la solution du problème : <span>$min_{x \in \mathbb{R}^{n}} f(x)$</span></li><li><strong>fxmin</strong>   : (Float) <span>$f(x_{min})$</span></li><li><strong>flag</strong>    : (Integer) un entier indiquant le critère sur lequel le programme à arrêter<ul><li><strong>0</strong>    : Convergence</li><li><strong>1</strong>    : stagnation du <span>$x$</span></li><li><strong>2</strong>    : stagnation du <span>$f$</span></li><li><strong>3</strong>    : nombre maximal d&#39;itération dépassé</li></ul></li><li><strong>nb_iters</strong> : (Integer)le nombre d&#39;iteration qu&#39;à fait le programme</li></ul><p><strong>Exemple d&#39;appel</strong></p><pre><code class="language-julia">algo=&quot;gct&quot;
f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2
gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]
hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]
x0 = [1; 0]
options = []
xmin, fxmin, flag,nb_iters = Regions_De_Confiance(algo,f,gradf,hessf,x0,options)</code></pre></div></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="Lagrangien_augmente.html">« La méthode du Lagrangien augmenté</a><a class="docs-footer-nextpage" href="Annexes.html">Annexes »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 9 November 2020 23:10">Monday 9 November 2020</span>. Using Julia version 1.4.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
